{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py3C0JzlsA7i",
        "outputId": "f615b009-0bc6-45ab-d03c-4ffb9f067029"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,824 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,243 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,688 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,788 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,099 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,542 kB]\n",
            "Fetched 20.5 MB in 7s (3,103 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 31 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.7 [186 kB]\n",
            "Fetched 186 kB in 1s (220 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126315 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.7_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.7) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.7) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Required libraries and dependencies installed.\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Install Libraries & Dependencies (CORRECTED)\n",
        "# Install poppler-utils (still potentially useful for PyPDF2 or other tools)\n",
        "!apt-get update && apt-get install -y poppler-utils\n",
        "\n",
        "# Install Python packages - Ensure pymupdf is installed, pdf2image is NOT\n",
        "!pip install -U langgraph langchain langchain_openai pypdf2 pillow pymupdf faiss-cpu langchain_community reportlab > /dev/null\n",
        "\n",
        "print(\"Required libraries and dependencies installed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFNf6g8isHeA",
        "outputId": "d8dfb935-2db8-4373-873d-b7c7bbc833c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported (PyMuPDF included, pdf2image removed) and credentials set.\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Import necessary libraries (CORRECTED)\n",
        "\n",
        "import os\n",
        "import json\n",
        "import uuid\n",
        "import re\n",
        "import smtplib\n",
        "from email.message import EmailMessage\n",
        "from typing import TypedDict, Annotated, List, Literal, Optional\n",
        "import operator\n",
        "from pathlib import Path\n",
        "import base64\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# Langchain & LangGraph imports\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage, AIMessage\n",
        "# --- Use Pydantic V2 directly ---\n",
        "# from langchain_core.pydantic_v1 import BaseModel, Field # Deprecated\n",
        "from pydantic import BaseModel, Field # Use Pydantic v2\n",
        "# --- End Pydantic V2 ---\n",
        "from langgraph.graph import StateGraph, END, START\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# PDF and Image processing\n",
        "import PyPDF2\n",
        "import fitz  # PyMuPDF library\n",
        "# --- REMOVED pdf2image import ---\n",
        "# from pdf2image import convert_from_path\n",
        "# --- END REMOVAL ---\n",
        "\n",
        "# Google Colab specific import for file upload\n",
        "from google.colab import files\n",
        "\n",
        "# --- Credentials ---\n",
        "openai_api_key = \"sk-...................\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "SENDER_EMAIL = \".........@...........\"\n",
        "SENDER_PASSWORD = \"......................\"\n",
        "\n",
        "print(\"Libraries imported and credentials set.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQkhsRr4sIWg",
        "outputId": "8954fad9-8cd6-4fbf-ad2a-6b6940cc04f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data file 'admission_data_v2.json' not found. Creating with default structure.\n",
            "Initial Data Loaded/Created (with income fields).\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Define Data Structure and JSON Handling (with income fields)\n",
        "\n",
        "# Define the structure for a single student application (ADDED family_income_lpa)\n",
        "DEFAULT_APPLICATION_STRUCTURE = {\n",
        "    \"app_id\": \"\",\n",
        "    \"applicant_name_marksheet\": None,\n",
        "    \"applicant_email\": None,\n",
        "    \"marks\": {\"class10_pcm_perc\": None, \"class12_pcm_perc\": None},\n",
        "    \"wbjee_rank\": None,\n",
        "    \"aadhaar_name\": None,\n",
        "    \"aadhaar_number\": None,\n",
        "    \"marksheet_pdf_path\": None,\n",
        "    \"aadhaar_pdf_path\": None,\n",
        "    \"family_income_lpa\": None, # ADDED: Family income in Lakhs Per Annum\n",
        "    \"loan_requested\": False,\n",
        "    \"extraction_status\": \"Pending\",\n",
        "    \"validation_status\": \"Pending\",\n",
        "    \"validation_reason\": None,\n",
        "    \"shortlist_status\": \"Pending\",\n",
        "    \"communication_status\": \"Not Sent\",\n",
        "    \"loan_status\": \"Not Applicable\",\n",
        "    \"loan_rejection_reason\": None,\n",
        "    \"fee_slip_status\": \"Not Sent\"\n",
        "}\n",
        "\n",
        "# Define the overall data structure (ADDED max_income_for_loan_lpa)\n",
        "DEFAULT_DATA_STRUCTURE = {\n",
        "    \"applications\": [],\n",
        "    \"eligibility_criteria\": {\n",
        "        \"min_class10_pcm_perc\": 60,\n",
        "        \"min_class12_pcm_perc\": 60,\n",
        "        \"max_wbjee_rank\": 10000,\n",
        "        \"max_income_for_loan_lpa\": 5.0, # ADDED: Max income (in Lakhs) for loan eligibility\n",
        "        \"required_docs\": [\"Marksheet\", \"Aadhaar\"]\n",
        "    },\n",
        "    \"university_capacity\": 3,\n",
        "    \"loan_budget\": 12000,\n",
        "    \"fee_amount\": 5000,\n",
        "    \"director_log\": [],\n",
        "    \"criteria_file_path\": None\n",
        "}\n",
        "\n",
        "DATA_FILE = \"admission_data_v2.json\"\n",
        "UPLOAD_DIR = \"uploaded_files\"\n",
        "\n",
        "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
        "\n",
        "# Function to initialize or load data\n",
        "def load_data():\n",
        "    if not os.path.exists(DATA_FILE):\n",
        "        print(f\"Data file '{DATA_FILE}' not found. Creating with default structure.\")\n",
        "        with open(DATA_FILE, 'w') as f:\n",
        "            json.dump(DEFAULT_DATA_STRUCTURE, f, indent=4)\n",
        "        return DEFAULT_DATA_STRUCTURE\n",
        "    try:\n",
        "        with open(DATA_FILE, 'r') as f:\n",
        "            print(f\"Loading data from '{DATA_FILE}'.\")\n",
        "            data = json.load(f)\n",
        "            if \"applications\" not in data or not isinstance(data[\"applications\"], list): data[\"applications\"] = []\n",
        "            if \"eligibility_criteria\" not in data: data[\"eligibility_criteria\"] = DEFAULT_DATA_STRUCTURE[\"eligibility_criteria\"]\n",
        "            if \"max_income_for_loan_lpa\" not in data[\"eligibility_criteria\"]: data[\"eligibility_criteria\"][\"max_income_for_loan_lpa\"] = DEFAULT_DATA_STRUCTURE[\"eligibility_criteria\"][\"max_income_for_loan_lpa\"]\n",
        "            for app in data.get(\"applications\", []): # Use .get for safety\n",
        "                if \"family_income_lpa\" not in app: app[\"family_income_lpa\"] = None\n",
        "            return data\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error decoding JSON from '{DATA_FILE}'. Creating default structure.\")\n",
        "        with open(DATA_FILE, 'w') as f: json.dump(DEFAULT_DATA_STRUCTURE, f, indent=4)\n",
        "        return DEFAULT_DATA_STRUCTURE\n",
        "\n",
        "# Function to save data\n",
        "def save_data(data):\n",
        "    try:\n",
        "        if \"applications\" not in data or not isinstance(data[\"applications\"], list): data[\"applications\"] = []; print(\"Warning: 'applications' key missing/invalid during save.\")\n",
        "        with open(DATA_FILE, 'w') as f: json.dump(data, f, indent=4)\n",
        "    except IOError as e: print(f\"Error saving data to '{DATA_FILE}': {e}\")\n",
        "    except TypeError as e: print(f\"Error serializing data for saving: {e}\")\n",
        "\n",
        "# Initialize/Load data\n",
        "admission_data = load_data()\n",
        "print(\"Initial Data Loaded/Created (with income fields).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xF3av30CuLT6",
        "outputId": "909491ff-6c95-415e-be17-f7a8065814e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions defined (using PyMuPDF for OCR).\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Helper Functions (Using PyMuPDF for OCR Image Gen)\n",
        "\n",
        "# --- PDF Text Extraction ---\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    # ... (implementation from previous step) ...\n",
        "    if not pdf_path or not os.path.exists(pdf_path): print(f\"Error: PDF path is invalid or file does not exist: {pdf_path}\"); return None\n",
        "    try:\n",
        "        text = \"\"; file = open(pdf_path, 'rb'); reader = PyPDF2.PdfReader(file)\n",
        "        if reader.is_encrypted: print(f\"Warning: PDF {pdf_path} is encrypted.\")\n",
        "        for page_num in range(len(reader.pages)):\n",
        "            page = reader.pages[page_num]; page_text = page.extract_text()\n",
        "            if page_text: text += page_text + \"\\n\"\n",
        "            else: print(f\"Warning: No text found on page {page_num+1} of {pdf_path}.\")\n",
        "        file.close()\n",
        "        if not text.strip(): print(f\"Warning: No text could be extracted from {pdf_path} overall.\"); return None\n",
        "        return text.strip()\n",
        "    except FileNotFoundError: print(f\"Error: PDF file not found at {pdf_path}\"); return None\n",
        "    except Exception as e: print(f\"Error extracting text from PDF {pdf_path}: {e}\"); return None\n",
        "\n",
        "# --- Pydantic model for OCR ---\n",
        "class AadhaarDetails(BaseModel): # Use Pydantic v2 BaseModel\n",
        "    name: Optional[str] = Field(None, description=\"The full name...\")\n",
        "    aadhaar_number: Optional[str] = Field(None, description=\"The 12-digit Aadhaar number...\")\n",
        "\n",
        "# --- Aadhaar OCR (Using PyMuPDF/fitz) ---\n",
        "llm_vision = ChatOpenAI(model=\"gpt-4o\", max_tokens=1024)\n",
        "structured_llm_vision = llm_vision.with_structured_output(AadhaarDetails)\n",
        "\n",
        "def perform_real_ocr_on_pdf(pdf_path):\n",
        "    \"\"\"Performs OCR on the first page of a PDF using PyMuPDF and OpenAI Vision.\"\"\"\n",
        "    if not pdf_path or not os.path.exists(pdf_path):\n",
        "        print(f\"Error: Aadhaar PDF path is invalid or file does not exist: {pdf_path}\")\n",
        "        return None\n",
        "    print(f\"Attempting OCR on {pdf_path} using PyMuPDF and GPT-4o Vision...\")\n",
        "    doc = None # Initialize doc to None for finally block\n",
        "    try:\n",
        "        doc = fitz.open(pdf_path)\n",
        "        if not doc or doc.page_count == 0:\n",
        "             print(f\"Error: Could not open or find pages in PDF: {pdf_path}\")\n",
        "             return None\n",
        "        page = doc.load_page(0)\n",
        "        pix = page.get_pixmap(dpi=200)\n",
        "        doc.close() # Close doc as soon as pixmap is obtained\n",
        "        doc = None # Set doc to None after closing\n",
        "\n",
        "        if not pix: print(f\"Error: Could not render page 0 to pixmap for {pdf_path}.\"); return None\n",
        "        img_bytes = pix.tobytes(\"png\")\n",
        "        if not img_bytes: print(f\"Error: Could not convert pixmap to bytes for {pdf_path}.\"); return None\n",
        "\n",
        "        base64_image = base64.b64encode(img_bytes).decode('utf-8'); image_url = f\"data:image/png;base64,{base64_image}\"\n",
        "        message = HumanMessage(content=[{\"type\": \"text\", \"text\": \"Extract the full name and the 12-digit Aadhaar number...\"}, {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}])\n",
        "        response = structured_llm_vision.invoke([message]); print(f\"Vision API Response (parsed): Name='{response.name}', Number='{response.aadhaar_number}'\")\n",
        "        extracted_name = response.name; extracted_number = response.aadhaar_number.replace(\" \", \"\") if response.aadhaar_number else None\n",
        "        if not extracted_name or not extracted_number: print(\"Warning: Vision API did not return both name and number.\")\n",
        "        elif len(extracted_number) != 12 or not extracted_number.isdigit(): print(f\"Warning: Extracted Aadhaar number '{extracted_number}' is not 12 digits or contains non-digits.\")\n",
        "        print(\"OCR successful.\")\n",
        "        return {\"name\": extracted_name, \"number\": extracted_number}\n",
        "    except Exception as e:\n",
        "        print(f\"Error during PyMuPDF/OCR process for {pdf_path}: {e}\")\n",
        "        return None\n",
        "    finally:\n",
        "        # Ensure the document is closed even if errors occur\n",
        "        if doc:\n",
        "            doc.close()\n",
        "            print(f\"Ensured fitz document for {pdf_path} is closed.\")\n",
        "\n",
        "\n",
        "# --- Marksheet Data Extraction ---\n",
        "# (Keep corrected version from previous step)\n",
        "def extract_marksheet_data(pdf_path):\n",
        "    # ... (implementation from previous step) ...\n",
        "    if not pdf_path or not os.path.exists(pdf_path): print(f\"Error: Marksheet PDF path is invalid or file does not exist: {pdf_path}\"); return None\n",
        "    print(f\"Extracting data from Marksheet: {pdf_path}...\"); text = extract_text_from_pdf(pdf_path)\n",
        "    if not text: print(f\"Failed to extract any text from marksheet: {pdf_path}\"); return None\n",
        "    data = {\"name\": None, \"email\": None, \"marks\": {}, \"wbjee_rank\": None}\n",
        "    try:\n",
        "        name_match = re.search(r\"Name\\s*[:\\-]?\\s*([A-Z][a-zA-Z\\s]+?)\\s*(?:\\n|Email|Roll)\", text, re.IGNORECASE); data[\"name\"] = name_match.group(1).strip() if name_match else None\n",
        "        if not data[\"name\"]: print(\"Warning: Could not extract Name from marksheet.\")\n",
        "        email_match = re.search(r\"[\\w\\.\\-+%]+@[\\w\\.\\-]+\\.[a-zA-Z]{2,}\", text); data[\"email\"] = email_match.group(0) if email_match else None\n",
        "        if not data[\"email\"]: print(\"Warning: Could not extract Email from marksheet.\")\n",
        "        c10_match = re.search(r\"Class\\s+10\\s+PCM\\s+(?:Percentage|%)\\s*[:\\-]?\\s*(\\d{1,3}(?:\\.\\d+)?)\", text, re.IGNORECASE)\n",
        "        c12_match = re.search(r\"Class\\s+12\\s+PCM\\s+(?:Percentage|%)\\s*[:\\-]?\\s*(\\d{1,3}(?:\\.\\d+)?)\", text, re.IGNORECASE)\n",
        "        data[\"marks\"] = {\"class10_pcm_perc\": float(c10_match.group(1)) if c10_match else None, \"class12_pcm_perc\": float(c12_match.group(1)) if c12_match else None}\n",
        "        if data[\"marks\"][\"class10_pcm_perc\"] is None: print(\"Warning: Could not extract Class 10 PCM %.\")\n",
        "        if data[\"marks\"][\"class12_pcm_perc\"] is None: print(\"Warning: Could not extract Class 12 PCM %.\")\n",
        "        rank_match = re.search(r\"WBJEE\\s+Rank\\s*[:\\-]?\\s*(\\d+)\", text, re.IGNORECASE); data[\"wbjee_rank\"] = int(rank_match.group(1)) if rank_match else None\n",
        "        if data[\"wbjee_rank\"] is None: print(\"Warning: Could not extract WBJEE Rank.\")\n",
        "        print(f\"Attempted Marksheet Extraction Results: {data}\"); return data\n",
        "    except Exception as e: print(f\"Error during regex extraction from marksheet {pdf_path}: {e}\"); return data\n",
        "\n",
        "# --- Criteria File Parsing ---\n",
        "# (Keep corrected version from previous step)\n",
        "def parse_criteria_file(file_path):\n",
        "    # ... (implementation from previous step) ...\n",
        "    if not file_path or not os.path.exists(file_path): print(f\"Error: Criteria file path is invalid or file does not exist: {file_path}\"); return DEFAULT_DATA_STRUCTURE[\"eligibility_criteria\"]\n",
        "    print(f\"Parsing criteria file: {file_path}...\"); text_content = extract_text_from_pdf(file_path)\n",
        "    if text_content is None: print(f\"Failed to extract text from criteria PDF: {file_path}. Using defaults.\"); return DEFAULT_DATA_STRUCTURE[\"eligibility_criteria\"]\n",
        "    criteria = {}; key_mapping = {\"min class 10 pcm perc\": \"min_class10_pcm_perc\", \"min class 12 pcm perc\": \"min_class12_pcm_perc\", \"max wbjee rank\": \"max_wbjee_rank\", \"required docs\": \"required_docs\", \"max income for loan lpa\": \"max_income_for_loan_lpa\", \"minimum class 10 pcm percentage\": \"min_class10_pcm_perc\", \"minimum class 12 pcm percentage\": \"min_class12_pcm_perc\", \"maximum wbjee rank\": \"max_wbjee_rank\", \"maximum income for loan lpa\": \"max_income_for_loan_lpa\"}\n",
        "    try:\n",
        "        for line in text_content.splitlines():\n",
        "            line = line.strip();\n",
        "            if not line or line.startswith('#'): continue\n",
        "            if ':' in line:\n",
        "                raw_key, value = line.split(':', 1); cleaned_key = raw_key.strip().lower(); code_key = key_mapping.get(cleaned_key)\n",
        "                if code_key:\n",
        "                    value = value.strip();\n",
        "                    try:\n",
        "                        if code_key == \"required_docs\": criteria[code_key] = [doc.strip() for doc in value.split(',')]\n",
        "                        elif '.' in value: criteria[code_key] = float(value)\n",
        "                        else: criteria[code_key] = int(value)\n",
        "                    except ValueError: criteria[code_key] = value\n",
        "                else: print(f\"Warning: Unrecognized criteria key '{raw_key.strip()}' in file. Skipping.\")\n",
        "        print(f\"Parsed Criteria: {criteria}\"); defaults = DEFAULT_DATA_STRUCTURE[\"eligibility_criteria\"]\n",
        "        for k, default_val in defaults.items():\n",
        "            if k not in criteria: print(f\"Warning: Criteria file missing key '{k}'. Using default: {default_val}\"); criteria[k] = default_val\n",
        "        return criteria\n",
        "    except Exception as e: print(f\"Error parsing extracted criteria text from {file_path}: {e}\"); return DEFAULT_DATA_STRUCTURE[\"eligibility_criteria\"]\n",
        "\n",
        "# --- Email Sending Function ---\n",
        "# (Keep as is)\n",
        "def send_email(recipient_email, subject, body):\n",
        "    # ... (implementation from previous step) ...\n",
        "    if not recipient_email: print(\"Skipping email: No recipient email provided.\"); return False, \"No recipient email\"\n",
        "    if not re.match(r\"[^@]+@[^@]+\\.[^@]+\", recipient_email): print(f\"Skipping email: Invalid recipient email format '{recipient_email}'.\"); return False, \"Invalid recipient email format\"\n",
        "    print(f\"Attempting to send email to {recipient_email} with subject: {subject}...\")\n",
        "    try:\n",
        "        msg = EmailMessage(); msg.set_content(body); msg['Subject'] = subject; msg['From'] = SENDER_EMAIL; msg['To'] = recipient_email\n",
        "        server = smtplib.SMTP_SSL('smtp.gmail.com', 465); server.login(SENDER_EMAIL, SENDER_PASSWORD); server.send_message(msg); server.quit()\n",
        "        print(f\"Email successfully sent to {recipient_email}.\"); return True, \"Email Sent Successfully\"\n",
        "    except smtplib.SMTPAuthenticationError: print(\"SMTP Authentication Error...\"); return False, \"SMTP Authentication Error\"\n",
        "    except Exception as e: print(f\"Error sending email to {recipient_email}: {e}\"); return False, f\"Failed to send email: {e}\"\n",
        "\n",
        "# --- Vector Store Creation Function ---\n",
        "# (Keep as is)\n",
        "def create_criteria_vectorstore(criteria_pdf_path, save_path=\"criteria_vectorstore\"):\n",
        "    # ... (implementation from previous step) ...\n",
        "    if not criteria_pdf_path or not os.path.exists(criteria_pdf_path): print(f\"Error: Cannot create vector store. Criteria PDF not found at {criteria_pdf_path}\"); return False\n",
        "    print(f\"\\n--- Creating FAISS Vector Store from: {criteria_pdf_path} ---\");\n",
        "    try:\n",
        "        print(\"Extracting text...\"); text_content = extract_text_from_pdf(criteria_pdf_path)\n",
        "        if not text_content: print(\"Failed to extract text.\"); return False\n",
        "        print(\"Splitting text...\"); text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50); documents = text_splitter.create_documents([text_content]); print(f\"Created {len(documents)} chunks.\")\n",
        "        print(\"Initializing embeddings...\");\n",
        "        if not os.getenv(\"OPENAI_API_KEY\"): print(\"Error: OPENAI_API_KEY not set.\"); return False\n",
        "        embeddings = OpenAIEmbeddings()\n",
        "        print(\"Creating FAISS index...\"); vectorstore = FAISS.from_documents(documents, embeddings); print(\"FAISS index created.\")\n",
        "        vectorstore.save_local(save_path); print(f\"FAISS vector store saved locally to: '{save_path}'\"); return True\n",
        "    except Exception as e: print(f\"An error occurred during vector store creation: {e}\"); return False\n",
        "\n",
        "print(\"Helper functions defined (using PyMuPDF for OCR).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9zrwvdauSoZ",
        "outputId": "93fa3ca8-a5cd-4ca0-ee7d-9edc8799f7c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangGraph state definitions complete.\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Define LangGraph State for Single App Processing (Keep as is)\n",
        "\n",
        "class ProcessAppState(TypedDict):\n",
        "    admission_data: dict\n",
        "    current_app_index: int\n",
        "    current_run_log: Annotated[List[str], operator.add]\n",
        "    extracted_marksheet_data: Optional[dict]\n",
        "    extracted_aadhaar_data: Optional[dict]\n",
        "\n",
        "class AdmissionState(TypedDict):\n",
        "    applications: List[dict]\n",
        "    eligibility_criteria: dict\n",
        "    university_capacity: int\n",
        "    loan_budget: int\n",
        "    fee_amount: int\n",
        "    director_log: Annotated[List[str], operator.add]\n",
        "    criteria_file_path: Optional[str]\n",
        "\n",
        "print(\"LangGraph state definitions complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFq6VRexugBb",
        "outputId": "9c8864ec-a475-4020-bb89-18b74bd64477"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent node functions defined (Corrected).\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Define Agent Nodes (CORRECTED - Validation & Communication Logic)\n",
        "\n",
        "# Helper to update the application list immutably\n",
        "def update_app_data(admission_data, index, updates):\n",
        "    if \"applications\" not in admission_data or not isinstance(admission_data[\"applications\"], list): print(\"Warning: 'applications' key missing/invalid during update.\"); return admission_data\n",
        "    new_apps = [app.copy() for app in admission_data[\"applications\"]]\n",
        "    if 0 <= index < len(new_apps): new_apps[index].update(updates)\n",
        "    else: print(f\"Warning: Invalid index {index} provided for update. List length: {len(new_apps)}\")\n",
        "    return {**admission_data, \"applications\": new_apps}\n",
        "\n",
        "# --- Node 1: Data Extraction ---\n",
        "# (Keep as is from previous correction)\n",
        "def data_extraction_node(state: ProcessAppState) -> ProcessAppState:\n",
        "    # ... (implementation from previous step) ...\n",
        "    app_index = state[\"current_app_index\"]\n",
        "    if not (0 <= app_index < len(state[\"admission_data\"].get(\"applications\", []))): print(f\"Error: Invalid current_app_index {app_index}...\"); run_log = [f\"Error: Invalid application index {app_index}.\"]; return {\"current_run_log\": run_log}\n",
        "    app_data = state[\"admission_data\"][\"applications\"][app_index]; applicant_name_initial = f'App_{app_index+1}'; print(f\"\\n--- Running Data Extraction for: {applicant_name_initial} (ID: {app_data.get('app_id', 'N/A')}) ---\"); run_log = [f\"Starting data extraction for {applicant_name_initial}.\"]\n",
        "    marksheet_path = app_data.get(\"marksheet_pdf_path\"); extracted_m_data = None\n",
        "    if marksheet_path: extracted_m_data = extract_marksheet_data(marksheet_path); run_log.append(f\"Marksheet data extraction attempted.\")\n",
        "    else: run_log.append(f\"Marksheet PDF path missing.\")\n",
        "    aadhaar_path = app_data.get(\"aadhaar_pdf_path\"); extracted_a_data = None\n",
        "    if aadhaar_path: extracted_a_data = perform_real_ocr_on_pdf(aadhaar_path); run_log.append(f\"Aadhaar data extraction attempted.\")\n",
        "    else: run_log.append(f\"Aadhaar PDF path missing.\")\n",
        "    status = \"Pending\"\n",
        "    if not marksheet_path or not aadhaar_path: status = \"Failed (Missing Files)\"; run_log.append(f\"Extraction marked Failed due to missing file paths.\")\n",
        "    elif extracted_m_data is None or extracted_a_data is None: status = \"Failed (Extraction Error)\"; run_log.append(f\"Extraction marked Failed due to errors during processing.\")\n",
        "    else: status = \"Attempted\"; run_log.append(f\"Data extraction attempted. Validation needed.\")\n",
        "    updated_admission_data = update_app_data(state[\"admission_data\"], app_index, {\"extraction_status\": status})\n",
        "    return {\"current_run_log\": run_log, \"extracted_marksheet_data\": extracted_m_data, \"extracted_aadhaar_data\": extracted_a_data, \"admission_data\": updated_admission_data}\n",
        "\n",
        "\n",
        "# --- Node 2: Validation (CORRECTED - Persist Extracted Details) ---\n",
        "def validation_node(state: ProcessAppState) -> ProcessAppState:\n",
        "    app_index = state[\"current_app_index\"]\n",
        "    admission_data = state[\"admission_data\"]\n",
        "    app_data = admission_data[\"applications\"][app_index]\n",
        "    applicant_name = app_data.get('applicant_name_marksheet') or app_data.get('aadhaar_name') or f'App_{app_index+1}'\n",
        "    print(f\"\\n--- Running Validation for: {applicant_name} ---\")\n",
        "    run_log = [f\"Starting validation for {applicant_name}.\"]\n",
        "\n",
        "    extracted_m = state.get(\"extracted_marksheet_data\")\n",
        "    extracted_a = state.get(\"extracted_aadhaar_data\")\n",
        "    criteria = admission_data.get(\"eligibility_criteria\", DEFAULT_DATA_STRUCTURE[\"eligibility_criteria\"])\n",
        "    validation_status = \"Pending\"\n",
        "    validation_reason = []\n",
        "    verified_name = None\n",
        "    applicant_email = None # Store extracted email here\n",
        "    aadhaar_number = None # Store extracted aadhaar here\n",
        "    marks = {}\n",
        "    rank = None\n",
        "\n",
        "    # --- Persist extracted data first ---\n",
        "    if extracted_m:\n",
        "        applicant_email = extracted_m.get(\"email\")\n",
        "        marks = extracted_m.get(\"marks\", {})\n",
        "        rank = extracted_m.get(\"wbjee_rank\")\n",
        "    if extracted_a:\n",
        "        aadhaar_number = str(extracted_a.get(\"number\", \"\")).replace(\" \", \"\")\n",
        "    # --- End Persist ---\n",
        "\n",
        "    if app_data.get(\"extraction_status\", \"\").startswith(\"Failed\"):\n",
        "        validation_status = \"Rejected\"; validation_reason.append(f\"Data Extraction Failed/Incomplete ({app_data.get('extraction_status')})\"); run_log.append(f\"Validation Rejected: Prerequisite data extraction failed.\")\n",
        "    elif not extracted_m or not extracted_a:\n",
        "         validation_status = \"Rejected\"; validation_reason.append(\"Missing extracted Marksheet or Aadhaar data.\"); run_log.append(\"Validation Rejected: Missing extracted data.\")\n",
        "    else:\n",
        "        # Validation checks using extracted_m and extracted_a\n",
        "        name_m = extracted_m.get(\"name\", \"\").strip().lower(); name_a = extracted_a.get(\"name\", \"\").strip().lower()\n",
        "        if name_m and name_a and name_m == name_a: verified_name = extracted_m.get('name').strip(); run_log.append(f\"Name match successful ('{verified_name}').\")\n",
        "        elif name_m and name_a: validation_status = \"Rejected\"; validation_reason.append(f\"Name Mismatch (M: '{extracted_m.get('name')}', A: '{extracted_a.get('name')}')\"); run_log.append(f\"Validation Rejected: Name Mismatch.\")\n",
        "        else: validation_status = \"Rejected\"; validation_reason.append(f\"Name Missing (M: '{extracted_m.get('name')}', A: '{extracted_a.get('name')}')\"); run_log.append(f\"Validation Rejected: Name Missing.\")\n",
        "\n",
        "        if len(aadhaar_number) == 12 and aadhaar_number.isdigit(): run_log.append(f\"Aadhaar number valid ('{aadhaar_number}').\")\n",
        "        else: validation_status = \"Rejected\"; validation_reason.append(f\"Invalid Aadhaar Number (Found: '{extracted_a.get('number')}')\"); run_log.append(f\"Validation Rejected: Invalid Aadhaar Number.\")\n",
        "\n",
        "        c10_marks = marks.get(\"class10_pcm_perc\"); c12_marks = marks.get(\"class12_pcm_perc\")\n",
        "        min_c10 = criteria.get(\"min_class10_pcm_perc\", 0); min_c12 = criteria.get(\"min_class12_pcm_perc\", 0)\n",
        "        if c10_marks is None or c10_marks < min_c10: validation_status = \"Rejected\"; validation_reason.append(f\"Class 10 PCM % ({c10_marks}) < Min ({min_c10})\"); run_log.append(f\"Validation Rejected: Class 10 Marks.\")\n",
        "        else: run_log.append(f\"Class 10 Marks OK ({c10_marks} >= {min_c10}).\")\n",
        "        if c12_marks is None or c12_marks < min_c12: validation_status = \"Rejected\"; validation_reason.append(f\"Class 12 PCM % ({c12_marks}) < Min ({min_c12})\"); run_log.append(f\"Validation Rejected: Class 12 Marks.\")\n",
        "        else: run_log.append(f\"Class 12 Marks OK ({c12_marks} >= {min_c12}).\")\n",
        "\n",
        "        max_rank = criteria.get(\"max_wbjee_rank\", 999999)\n",
        "        if rank is None or rank > max_rank: validation_status = \"Rejected\"; validation_reason.append(f\"WBJEE Rank ({rank}) > Max ({max_rank})\"); run_log.append(f\"Validation Rejected: WBJEE Rank.\")\n",
        "        else: run_log.append(f\"WBJEE Rank OK ({rank} <= {max_rank}).\")\n",
        "\n",
        "        if not validation_reason: validation_status = \"Verified\"; run_log.append(\"Overall Validation Successful.\")\n",
        "        else: validation_status = \"Rejected\"\n",
        "\n",
        "    # Prepare updates for the main data structure\n",
        "    updates = {\n",
        "        \"validation_status\": validation_status,\n",
        "        \"validation_reason\": \", \".join(validation_reason) if validation_reason else None,\n",
        "        \"applicant_name_marksheet\": verified_name or extracted_m.get('name') if extracted_m else None, # Store best available name\n",
        "        \"applicant_email\": applicant_email, # Store extracted email\n",
        "        \"marks\": marks, # Store extracted marks\n",
        "        \"wbjee_rank\": rank, # Store extracted rank\n",
        "        \"aadhaar_name\": extracted_a.get(\"name\") if extracted_a else None, # Store name from aadhaar\n",
        "        \"aadhaar_number\": aadhaar_number, # Store extracted aadhaar number\n",
        "    }\n",
        "    return {\"current_run_log\": run_log, \"admission_data\": update_app_data(admission_data, app_index, updates)}\n",
        "\n",
        "\n",
        "# --- Node 3: Communication (CORRECTED - Fetch Latest Name/Email) ---\n",
        "def communication_node(state: ProcessAppState) -> ProcessAppState:\n",
        "    app_index = state[\"current_app_index\"]\n",
        "    admission_data = state[\"admission_data\"]\n",
        "    app_data = admission_data[\"applications\"][app_index] # Get the latest app_data\n",
        "    # --- Fetch latest name and email from app_data ---\n",
        "    applicant_name = app_data.get('applicant_name_marksheet') or app_data.get('aadhaar_name') or f'Applicant {app_index+1}'\n",
        "    recipient = app_data.get(\"applicant_email\")\n",
        "    # --- End Fetch ---\n",
        "    print(f\"\\n--- Running Communication for: {applicant_name} ---\")\n",
        "    run_log = [f\"Preparing communication for {applicant_name}.\"]\n",
        "    subject = \"\"; body = \"\"; comm_status = \"Not Sent\"\n",
        "\n",
        "    # Use .get() for safer access to validation_status\n",
        "    current_validation_status = app_data.get(\"validation_status\")\n",
        "\n",
        "    if current_validation_status == \"Verified\":\n",
        "        subject = \"Application Status: Verification Successful\"; body = f\"Dear {applicant_name},\\n\\nCongratulations! Your application documents and eligibility have been successfully verified...\\n\\nRegards,\\nAdmission Team\"; comm_status = \"Verification Success Sent\"\n",
        "    elif current_validation_status == \"Rejected\":\n",
        "        subject = \"Application Status: Update Required / Rejection\"; reason = app_data.get('validation_reason', 'details not available'); body = f\"Dear {applicant_name},\\n\\nWe regret to inform you that your application could not be verified due to:\\n- {reason}\\n\\nRegards,\\nAdmission Team\"; comm_status = \"Rejection Sent\"\n",
        "    else:\n",
        "         run_log.append(f\"No communication sent (Validation Status: {current_validation_status}).\"); comm_status = \"Pending Validation\"\n",
        "         return {\"current_run_log\": run_log, \"admission_data\": update_app_data(admission_data, app_index, {\"communication_status\": comm_status})}\n",
        "\n",
        "    # --- Check recipient before sending ---\n",
        "    if recipient:\n",
        "        success, message = send_email(recipient, subject, body)\n",
        "        if success: run_log.append(f\"Email sent to {recipient} regarding validation status.\")\n",
        "        else: run_log.append(f\"Failed to send validation status email to {recipient}: {message}\"); comm_status = \"Email Failed\"\n",
        "    else:\n",
        "        run_log.append(f\"Cannot send email: Recipient email address missing for {applicant_name}.\")\n",
        "        comm_status = \"Email Failed (Missing Address)\"\n",
        "    # --- End Check ---\n",
        "\n",
        "    return {\"current_run_log\": run_log, \"admission_data\": update_app_data(admission_data, app_index, {\"communication_status\": comm_status})}\n",
        "\n",
        "# --- Node 4: Loan Processing Check ---\n",
        "# (Keep as is - logic depends on external shortlisting)\n",
        "def loan_processing_node(state: ProcessAppState) -> ProcessAppState:\n",
        "    # ... (implementation from previous step) ...\n",
        "    app_index = state[\"current_app_index\"]; admission_data = state[\"admission_data\"]; app_data = admission_data[\"applications\"][app_index]\n",
        "    applicant_name = app_data.get('applicant_name_marksheet') or app_data.get('aadhaar_name') or f'App_{app_index+1}'\n",
        "    print(f\"\\n--- Running Loan Processing Check for: {applicant_name} ---\"); run_log = [f\"Checking loan status for {applicant_name}.\"]\n",
        "    updates = {}\n",
        "    if app_data.get(\"validation_status\") == \"Verified\":\n",
        "        if app_data.get(\"loan_requested\", False): updates[\"loan_status\"] = \"Pending Shortlisting\"; run_log.append(\"Loan requested. Status set to Pending Shortlisting.\"); print(f\"Loan request noted for {applicant_name}.\")\n",
        "        else: updates[\"loan_status\"] = \"Not Requested\"; run_log.append(\"Loan not requested.\"); print(f\"Loan not requested by {applicant_name}.\")\n",
        "    else: updates[\"loan_status\"] = \"Not Applicable\"; run_log.append(f\"Loan not applicable (Validation: {app_data.get('validation_status')}).\"); print(f\"Loan not applicable for {applicant_name}.\")\n",
        "    updates[\"fee_slip_status\"] = \"Pending Shortlisting\"\n",
        "    return {\"current_run_log\": run_log, \"admission_data\": update_app_data(admission_data, app_index, updates)}\n",
        "\n",
        "\n",
        "# --- Node 5: Admission Officer Report (CORRECTED - Safer Access) ---\n",
        "llm_report = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
        "def admission_officer_agent(state: AdmissionState) -> AdmissionState:\n",
        "    print(\"\\n--- Running Admission Officer Agent (Generating Report) ---\"); log_entry = \"Generating final admission status report...\"; print(log_entry)\n",
        "    admission_data = state; status_summary = []\n",
        "    # --- Use .get() for safer access ---\n",
        "    for app in admission_data.get(\"applications\", []):\n",
        "        app_name = app.get('applicant_name_marksheet') or app.get('aadhaar_name') or app.get('app_id', 'N/A')\n",
        "        validation_reason = f\" (Reason: {app.get('validation_reason', 'N/A')})\" if app.get('validation_status') == 'Rejected' else \"\"\n",
        "        loan_reason = f\" (Loan Reason: {app.get('loan_rejection_reason', 'N/A')})\" if app.get('loan_status') == 'Rejected' else \"\"\n",
        "        status_summary.append(\n",
        "            f\"- {app_name}: \"\n",
        "            f\"Docs={app.get('extraction_status', 'N/A')}, Validation={app.get('validation_status', 'N/A')}{validation_reason}, \"\n",
        "            f\"Shortlist={app.get('shortlist_status', 'N/A')}, Comm={app.get('communication_status', 'N/A')}, \"\n",
        "            f\"Loan={app.get('loan_status', 'N/A')}{loan_reason}, FeeSlip={app.get('fee_slip_status', 'N/A')}\"\n",
        "        )\n",
        "    # --- End Safer Access ---\n",
        "    summary_text = \"\\n\".join(status_summary); log_limit = 30; previous_logs = \"\\n\".join(admission_data.get(\"director_log\", [])[-log_limit:])\n",
        "    prompt = f\"\"\"You are the Admission Officer... Final Application Status Summary:\\n{summary_text}\\n\\nUniversity Capacity: {admission_data.get('university_capacity', 'N/A')}\\nRemaining Loan Budget: {admission_data.get('loan_budget', 'N/A')}\\nFee Amount: {admission_data.get('fee_amount', 'N/A')}\\n\\nGenerate a brief report...\"\"\"\n",
        "    try:\n",
        "        response = llm_report.invoke([HumanMessage(content=prompt)]); report = response.content; print(\"Report Generated by LLM.\")\n",
        "    except Exception as e: report = f\"Error generating report: {e}\"; print(f\"LLM Error: {e}\")\n",
        "    updated_log = admission_data.get(\"director_log\", []) + [log_entry, f\"FINAL REPORT:\\n{report}\"]\n",
        "    return {\"director_log\": updated_log}\n",
        "\n",
        "print(\"Agent node functions defined (Corrected).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JhouwzluySa",
        "outputId": "4a4dee7e-17d0-473e-9ad4-ae8116174902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Graphs defined and compiled with correct state types.\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: Define Graph Structure (Using Corrected State Types)\n",
        "\n",
        "# --- Graph for Single Application Processing ---\n",
        "process_app_workflow = StateGraph(ProcessAppState) # Use ProcessAppState\n",
        "\n",
        "process_app_workflow.add_node(\"extract_data\", data_extraction_node)\n",
        "process_app_workflow.add_node(\"validate_application\", validation_node)\n",
        "process_app_workflow.add_node(\"communicate_status\", communication_node)\n",
        "process_app_workflow.add_node(\"check_loan_request\", loan_processing_node)\n",
        "\n",
        "process_app_workflow.add_edge(START, \"extract_data\")\n",
        "process_app_workflow.add_edge(\"extract_data\", \"validate_application\")\n",
        "process_app_workflow.add_edge(\"validate_application\", \"communicate_status\")\n",
        "process_app_workflow.add_edge(\"communicate_status\", \"check_loan_request\")\n",
        "process_app_workflow.add_edge(\"check_loan_request\", END)\n",
        "\n",
        "compiled_process_app_graph = process_app_workflow.compile()\n",
        "\n",
        "# --- Graph for Final Report ---\n",
        "report_workflow = StateGraph(AdmissionState) # Use AdmissionState\n",
        "\n",
        "report_workflow.add_node(\"admission_officer_agent\", admission_officer_agent)\n",
        "report_workflow.add_edge(START, \"admission_officer_agent\")\n",
        "report_workflow.add_edge(\"admission_officer_agent\", END)\n",
        "compiled_report_graph = report_workflow.compile()\n",
        "\n",
        "print(\"Graphs defined and compiled with correct state types.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nd_JHxbtu1Qy",
        "outputId": "9d753713-1e2e-4b21-a1e7-86fc00585b2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Step 1: Initial Setup & File Uploads ===\n",
            "Loading data from 'admission_data_v2.json'.\n",
            "\n",
            "--- Please upload the Criteria File you created (e.g., criteria.pdf) ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5259e0ce-bc10-4ef6-b452-7b488b427c2e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5259e0ce-bc10-4ef6-b452-7b488b427c2e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving criteria.pdf to criteria.pdf\n",
            "Criteria file 'criteria.pdf' uploaded and saved to uploaded_files/criteria.pdf\n",
            "Parsing criteria file: uploaded_files/criteria.pdf...\n",
            "Parsed Criteria: {'min_class10_pcm_perc': 75, 'min_class12_pcm_perc': 70, 'max_wbjee_rank': 5000, 'required_docs': ['ID Proof', 'Marksheet', 'Photo']}\n",
            "Warning: Criteria file missing key 'max_income_for_loan_lpa'. Using default: 5.0\n",
            "\n",
            "--- Creating FAISS Vector Store from: uploaded_files/criteria.pdf ---\n",
            "Extracting text...\n",
            "Splitting text...\n",
            "Created 1 chunks.\n",
            "Initializing embeddings...\n",
            "Creating FAISS index...\n",
            "FAISS index created.\n",
            "FAISS vector store saved locally to: 'criteria_faiss_index'\n",
            "\n",
            "Do you want to upload files for an application? (yes/no): yes\n",
            "\n",
            "--- Uploading files for New Application ID: 978e77af-59aa-42a6-9dec-ad747447ac4d ---\n",
            "Please upload the Marksheet PDF:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e318b481-bc62-4e1c-af93-607596acae7f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e318b481-bc62-4e1c-af93-607596acae7f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving marksheet.pdf to marksheet.pdf\n",
            "Marksheet 'marksheet.pdf' saved as uploaded_files/978e77af-59aa-42a6-9dec-ad747447ac4d_marksheet.pdf\n",
            "Please upload the Aadhaar Card PDF:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aaeb838f-48f9-42a0-8bcc-0743a5af112f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-aaeb838f-48f9-42a0-8bcc-0743a5af112f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving adhaar.pdf to adhaar.pdf\n",
            "Aadhaar 'adhaar.pdf' saved as uploaded_files/978e77af-59aa-42a6-9dec-ad747447ac4d_aadhaar.pdf\n",
            "Enter applicant's family income (in Lakhs Per Annum, e.g., 4.5): 3\n",
            "Does this applicant request a loan? (yes/no): yes\n",
            "Application entry created for ID: 978e77af-59aa-42a6-9dec-ad747447ac4d\n",
            "\n",
            "Do you want to upload files for an application? (yes/no): no\n",
            "\n",
            "=== Step 2: Process 1 Application(s) via LangGraph ===\n",
            "\n",
            ">>> Processing Application 1/1 (ID: 978e77af-59aa-42a6-9dec-ad747447ac4d) <<<\n",
            "\n",
            "--- Running Data Extraction for: App_1 (ID: 978e77af-59aa-42a6-9dec-ad747447ac4d) ---\n",
            "Extracting data from Marksheet: uploaded_files/978e77af-59aa-42a6-9dec-ad747447ac4d_marksheet.pdf...\n",
            "Attempted Marksheet Extraction Results: {'name': 'Anjali', 'email': 'arkodeep3404@gmail.com', 'marks': {'class10_pcm_perc': 88.33, 'class12_pcm_perc': 82.0}, 'wbjee_rank': 2150}\n",
            "Attempting OCR on uploaded_files/978e77af-59aa-42a6-9dec-ad747447ac4d_aadhaar.pdf using PyMuPDF and GPT-4o Vision...\n",
            "Vision API Response (parsed): Name='Anjali', Number='2268 1622 3671'\n",
            "OCR successful.\n",
            "\n",
            "--- Running Validation for: App_1 ---\n",
            "\n",
            "--- Running Communication for: Anjali ---\n",
            "Attempting to send email to arkodeep3404@gmail.com with subject: Application Status: Verification Successful...\n",
            "Email successfully sent to arkodeep3404@gmail.com.\n",
            "\n",
            "--- Running Loan Processing Check for: Anjali ---\n",
            "Loan request noted for Anjali.\n",
            ">>> Finished Graph Processing for Application 1/1 (Anjali) <<<\n",
            "\n",
            "=== Step 3: Final Shortlisting Based on Capacity ===\n",
            "Final Shortlist: Anjali (Rank: 2150)\n",
            "Final shortlisting complete.\n",
            "\n",
            "=== Step 4: Process Loans & Fee Slips for Shortlisted ===\n",
            "Loan Eligibility: Max Family Income = 5.0 LPA\n",
            "Loan Approved for Anjali.\n",
            "Attempting to send email to arkodeep3404@gmail.com with subject: Admission Update: Loan Approved & Fee Info...\n",
            "Email successfully sent to arkodeep3404@gmail.com.\n",
            "Fee slip sent to Anjali.\n",
            "Final loan processing and fee slip dispatch complete.\n",
            "\n",
            "=== Step 5: Generate Final Director Report ===\n",
            "\n",
            "--- Running Admission Officer Agent (Generating Report) ---\n",
            "Generating final admission status report...\n",
            "Report Generated by LLM.\n",
            "\n",
            "=== Admission Process Complete ===\n",
            "\n",
            "Final State (saved to admission_data_v2.json):\n",
            "\n",
            "--- Final Director's Log ---\n",
            "- Starting data extraction for App_1.\n",
            "- Marksheet data extraction attempted.\n",
            "- Aadhaar data extraction attempted.\n",
            "- Data extraction attempted. Validation needed.\n",
            "- Starting validation for App_1.\n",
            "- Name match successful ('Anjali').\n",
            "- Aadhaar number valid ('226816223671').\n",
            "- Class 10 Marks OK (88.33 >= 75).\n",
            "- Class 12 Marks OK (82.0 >= 70).\n",
            "- WBJEE Rank OK (2150 <= 5000).\n",
            "- Overall Validation Successful.\n",
            "- Preparing communication for Anjali.\n",
            "- Email sent to arkodeep3404@gmail.com regarding validation status.\n",
            "- Checking loan status for Anjali.\n",
            "- Loan requested. Status set to Pending Shortlisting.\n",
            "- Starting final shortlisting based on capacity.\n",
            "- Final Shortlist: Anjali (Rank: 2150).\n",
            "- Starting final loan processing and fee slip dispatch for shortlisted.\n",
            "- Loan Approved for Anjali. Budget left: 7000.\n",
            "- Fee/Loan email to Anjali: Success\n",
            "- Fee slip sent to Anjali.\n",
            "- Starting data extraction for App_1.\n",
            "- Marksheet data extraction attempted.\n",
            "- Aadhaar data extraction attempted.\n",
            "- Data extraction attempted. Validation needed.\n",
            "- Starting validation for App_1.\n",
            "- Name match successful ('Anjali').\n",
            "- Aadhaar number valid ('226816223671').\n",
            "- Class 10 Marks OK (88.33 >= 75).\n",
            "- Class 12 Marks OK (82.0 >= 70).\n",
            "- WBJEE Rank OK (2150 <= 5000).\n",
            "- Overall Validation Successful.\n",
            "- Preparing communication for Anjali.\n",
            "- Email sent to arkodeep3404@gmail.com regarding validation status.\n",
            "- Checking loan status for Anjali.\n",
            "- Loan requested. Status set to Pending Shortlisting.\n",
            "- Starting final shortlisting based on capacity.\n",
            "- Final Shortlist: Anjali (Rank: 2150).\n",
            "- Starting final loan processing and fee slip dispatch for shortlisted.\n",
            "- Loan Approved for Anjali. Budget left: 7000.\n",
            "- Fee/Loan email to Anjali: Success\n",
            "- Fee slip sent to Anjali.\n",
            "- Generating final admission status report...\n",
            "- FINAL REPORT:\n",
            "Based on the final application status summary, Anjali has successfully completed all necessary documentation, her validation has been verified, and she has been shortlisted for admission. A final decision has been sent to her, her loan has been approved, and the fee slip has been sent.\n",
            "\n",
            "With a university capacity of 3, Anjali's successful application brings the total number of admitted students to 1. There is still room for 2 more students to be admitted.\n",
            "\n",
            "Additionally, there is a remaining loan budget of 7000, which is more than enough to cover Anjali's approved loan amount of 5000.\n",
            "\n",
            "Overall, Anjali's application has been successful and she is on track to join the university pending the payment of her fees.\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: Main Application Flow (Using Corrected Log Handling)\n",
        "\n",
        "import time\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "def run_admission_process_with_uploads():\n",
        "    print(\"\\n=== Step 1: Initial Setup & File Uploads ===\")\n",
        "    admission_data = load_data()\n",
        "    admission_data[\"applications\"] = []\n",
        "    admission_data[\"director_log\"] = []\n",
        "\n",
        "    # --- Upload Criteria File ---\n",
        "    print(\"\\n--- Please upload the Criteria File you created (e.g., criteria.pdf) ---\")\n",
        "    uploaded_criteria = files.upload(); criteria_file_path = None\n",
        "    if not uploaded_criteria: print(\"No criteria file uploaded. Using default criteria.\"); admission_data[\"criteria_file_path\"] = None; admission_data[\"eligibility_criteria\"] = DEFAULT_DATA_STRUCTURE[\"eligibility_criteria\"]\n",
        "    else:\n",
        "        criteria_filename = list(uploaded_criteria.keys())[0]; criteria_path = os.path.join(UPLOAD_DIR, criteria_filename); shutil.move(criteria_filename, criteria_path)\n",
        "        print(f\"Criteria file '{criteria_filename}' uploaded and saved to {criteria_path}\"); admission_data[\"criteria_file_path\"] = criteria_path; admission_data[\"eligibility_criteria\"] = parse_criteria_file(criteria_path)\n",
        "\n",
        "    # --- Create Vector Store (Demo Only) ---\n",
        "    current_criteria_path = admission_data.get(\"criteria_file_path\")\n",
        "    if current_criteria_path: create_criteria_vectorstore(current_criteria_path, save_path=\"criteria_faiss_index\")\n",
        "    else: print(\"Skipping vector store creation.\")\n",
        "    save_data(admission_data)\n",
        "\n",
        "    # --- Upload Application Files Loop ---\n",
        "    while True:\n",
        "        add_another = input(\"\\nDo you want to upload files for an application? (yes/no): \").lower()\n",
        "        if add_another != 'yes': break\n",
        "        app_id = str(uuid.uuid4()); print(f\"\\n--- Uploading files for New Application ID: {app_id} ---\")\n",
        "        print(\"Please upload the Marksheet PDF:\"); uploaded_marksheet = files.upload(); marksheet_path = None\n",
        "        if uploaded_marksheet: marksheet_filename = list(uploaded_marksheet.keys())[0]; marksheet_path = os.path.join(UPLOAD_DIR, f\"{app_id}_marksheet.pdf\"); shutil.move(marksheet_filename, marksheet_path); print(f\"Marksheet '{marksheet_filename}' saved as {marksheet_path}\")\n",
        "        else: print(\"Marksheet upload skipped.\"); continue\n",
        "        print(\"Please upload the Aadhaar Card PDF:\"); uploaded_aadhaar = files.upload(); aadhaar_path = None\n",
        "        if uploaded_aadhaar: aadhaar_filename = list(uploaded_aadhaar.keys())[0]; aadhaar_path = os.path.join(UPLOAD_DIR, f\"{app_id}_aadhaar.pdf\"); shutil.move(aadhaar_filename, aadhaar_path); print(f\"Aadhaar '{aadhaar_filename}' saved as {aadhaar_path}\")\n",
        "        else: print(\"Aadhaar upload skipped.\"); continue\n",
        "        family_income_str = input(\"Enter applicant's family income (in Lakhs Per Annum, e.g., 4.5): \"); family_income_lpa = None\n",
        "        try: family_income_lpa = float(family_income_str)\n",
        "        except ValueError: print(\"Invalid income input. Storing as None.\")\n",
        "        loan_req_input = input(\"Does this applicant request a loan? (yes/no): \").lower(); loan_requested = loan_req_input == 'yes'\n",
        "        new_app = DEFAULT_APPLICATION_STRUCTURE.copy(); new_app[\"app_id\"] = app_id; new_app[\"marksheet_pdf_path\"] = marksheet_path; new_app[\"aadhaar_pdf_path\"] = aadhaar_path; new_app[\"loan_requested\"] = loan_requested; new_app[\"family_income_lpa\"] = family_income_lpa\n",
        "        admission_data[\"applications\"].append(new_app); print(f\"Application entry created for ID: {app_id}\"); save_data(admission_data)\n",
        "\n",
        "    if not admission_data[\"applications\"]: print(\"\\nNo applications were added/found. Exiting process.\"); return\n",
        "\n",
        "    print(f\"\\n=== Step 2: Process {len(admission_data['applications'])} Application(s) via LangGraph ===\")\n",
        "    num_applications = len(admission_data[\"applications\"])\n",
        "    for i in range(num_applications):\n",
        "        app_id_for_log = admission_data['applications'][i].get('app_id', 'UNKNOWN_ID'); applicant_name_for_log = f'App_{i+1}'\n",
        "        print(f\"\\n>>> Processing Application {i+1}/{num_applications} (ID: {app_id_for_log}) <<<\")\n",
        "        state_for_this_run = {\"admission_data\": admission_data, \"current_app_index\": i, \"current_run_log\": [], \"extracted_marksheet_data\": None, \"extracted_aadhaar_data\": None}\n",
        "        config = {\"configurable\": {\"thread_id\": f\"app_process_{app_id_for_log}\"}}\n",
        "        try:\n",
        "            final_state_after_app = compiled_process_app_graph.invoke(state_for_this_run, config=config)\n",
        "            admission_data = final_state_after_app[\"admission_data\"]\n",
        "            admission_data.setdefault(\"director_log\", []).extend(final_state_after_app.get(\"current_run_log\", [])) # Safer append\n",
        "            save_data(admission_data)\n",
        "            applicant_name_final = admission_data['applications'][i].get('applicant_name_marksheet') or admission_data['applications'][i].get('aadhaar_name') or f'App_{i+1}'\n",
        "            print(f\">>> Finished Graph Processing for Application {i+1}/{num_applications} ({applicant_name_final}) <<<\")\n",
        "            time.sleep(1)\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR processing application {i+1} (ID: {app_id_for_log}) via graph: {e}\")\n",
        "            admission_data.setdefault(\"director_log\", []).append(f\"ERROR processing {applicant_name_for_log} (ID: {app_id_for_log}) via graph: {e}\")\n",
        "            try: admission_data[\"applications\"][i][\"validation_status\"] = \"Processing Error\"; admission_data[\"applications\"][i][\"validation_reason\"] = str(e)\n",
        "            except IndexError: print(\"Could not update application status due to index error.\")\n",
        "            save_data(admission_data)\n",
        "\n",
        "    print(\"\\n=== Step 3: Final Shortlisting Based on Capacity ===\")\n",
        "    verified_apps = [(i, app) for i, app in enumerate(admission_data[\"applications\"]) if app.get(\"validation_status\") == \"Verified\"]\n",
        "    verified_apps.sort(key=lambda item: item[1].get(\"wbjee_rank\") if isinstance(item[1].get(\"wbjee_rank\"), int) else 999999)\n",
        "    shortlisted_count = 0; capacity = admission_data.get(\"university_capacity\", 0); log_entries = [\"Starting final shortlisting based on capacity.\"]\n",
        "    for i, app in verified_apps:\n",
        "        applicant_name = app.get('applicant_name_marksheet') or app.get('aadhaar_name') or f'App_{i+1}'; rank = app.get('wbjee_rank', 'N/A')\n",
        "        if shortlisted_count < capacity: admission_data[\"applications\"][i][\"shortlist_status\"] = \"Shortlisted\"; log_entries.append(f\"Final Shortlist: {applicant_name} (Rank: {rank}).\"); print(f\"Final Shortlist: {applicant_name} (Rank: {rank})\"); shortlisted_count += 1\n",
        "        else: admission_data[\"applications\"][i][\"shortlist_status\"] = \"Waitlisted\"; log_entries.append(f\"Waitlisted (Capacity Full): {applicant_name} (Rank: {rank}).\"); print(f\"Waitlisted: {applicant_name} (Rank: {rank})\")\n",
        "    admission_data.setdefault(\"director_log\", []).extend(log_entries); save_data(admission_data); print(\"Final shortlisting complete.\")\n",
        "\n",
        "    print(\"\\n=== Step 4: Process Loans & Fee Slips for Shortlisted ===\")\n",
        "    log_entries = [\"Starting final loan processing and fee slip dispatch for shortlisted.\"]; current_budget = admission_data.get(\"loan_budget\", 0); fee_amount = admission_data.get(\"fee_amount\", 0)\n",
        "    max_income_for_loan = admission_data.get(\"eligibility_criteria\", {}).get(\"max_income_for_loan_lpa\", 5.0); print(f\"Loan Eligibility: Max Family Income = {max_income_for_loan} LPA\")\n",
        "    for i, app in enumerate(admission_data[\"applications\"]):\n",
        "         applicant_name = app.get('applicant_name_marksheet') or app.get('aadhaar_name') or f'App_{i+1}'\n",
        "         if app.get(\"shortlist_status\") == \"Shortlisted\":\n",
        "             loan_status = \"Not Applicable\"; loan_reason = None; fee_status = \"Not Sent\"; email_subject = \"\"; email_body = \"\"; recipient_email = app.get(\"applicant_email\")\n",
        "             if app.get(\"loan_requested\"):\n",
        "                 family_income = app.get(\"family_income_lpa\")\n",
        "                 if family_income is not None and family_income > max_income_for_loan: loan_status = \"Rejected\"; loan_reason = f\"Income ({family_income} LPA) > Limit ({max_income_for_loan} LPA)\"; log_entries.append(f\"Loan Rejected for {applicant_name} ({loan_reason}).\"); print(f\"Loan Rejected for {applicant_name} (Income).\"); email_subject = \"Admission Update: Fee Info (Loan Status)\"; email_body = f\"Dear {applicant_name},\\n\\nCongrats...\\n\\nLoan rejected due to income...\\n\\nRegards,\\nFinance Team\"\n",
        "                 elif current_budget >= fee_amount: loan_status = \"Approved\"; current_budget -= fee_amount; log_entries.append(f\"Loan Approved for {applicant_name}. Budget left: {current_budget}.\"); print(f\"Loan Approved for {applicant_name}.\"); email_subject = \"Admission Update: Loan Approved & Fee Info\"; email_body = f\"Dear {applicant_name},\\n\\nCongrats...\\n\\nLoan approved...\\n\\nRegards,\\nFinance Team\"\n",
        "                 else: loan_status = \"Rejected\"; loan_reason = f\"Insufficient Budget ({current_budget})\"; log_entries.append(f\"Loan Rejected for {applicant_name} (Budget).\"); print(f\"Loan Rejected for {applicant_name} (Budget).\"); email_subject = \"Admission Update: Fee Info (Loan Status)\"; email_body = f\"Dear {applicant_name},\\n\\nCongrats...\\n\\nLoan rejected due to budget...\\n\\nRegards,\\nFinance Team\"\n",
        "             else: loan_status = \"Not Requested\"; log_entries.append(f\"Loan not requested by {applicant_name}.\"); print(f\"Loan not requested by {applicant_name}.\"); email_subject = \"Admission Update: Fee Info\"; email_body = f\"Dear {applicant_name},\\n\\nCongrats...\\n\\nFee slip attached...\"\n",
        "             # --- Added check for recipient_email before sending ---\n",
        "             if recipient_email:\n",
        "                 success, msg = send_email(recipient_email, email_subject, email_body); log_entries.append(f\"Fee/Loan email to {applicant_name}: {'Success' if success else 'Failed: '+msg}\")\n",
        "             else:\n",
        "                 log_entries.append(f\"Skipped Fee/Loan email to {applicant_name}: No email address found.\")\n",
        "             # --- End check ---\n",
        "             fee_status = \"Sent\"; log_entries.append(f\"Fee slip sent to {applicant_name}.\"); print(f\"Fee slip sent to {applicant_name}.\")\n",
        "             admission_data[\"applications\"][i][\"loan_status\"] = loan_status; admission_data[\"applications\"][i][\"loan_rejection_reason\"] = loan_reason; admission_data[\"applications\"][i][\"fee_slip_status\"] = fee_status; admission_data[\"applications\"][i][\"communication_status\"] = \"Final Decision Sent\"\n",
        "    admission_data[\"loan_budget\"] = current_budget; admission_data.setdefault(\"director_log\", []).extend(log_entries); save_data(admission_data); print(\"Final loan processing and fee slip dispatch complete.\")\n",
        "\n",
        "    print(\"\\n=== Step 5: Generate Final Director Report ===\")\n",
        "    config_report = {\"configurable\": {\"thread_id\": \"admission_process_final_report\"}}\n",
        "    try:\n",
        "        final_report_state_update = compiled_report_graph.invoke(admission_data, config=config_report)\n",
        "        admission_data[\"director_log\"] = final_report_state_update[\"director_log\"]\n",
        "    except Exception as e:\n",
        "         print(f\"ERROR generating final report: {e}\")\n",
        "         admission_data.setdefault(\"director_log\", []).append(f\"ERROR generating final report: {e}\")\n",
        "    save_data(admission_data)\n",
        "\n",
        "    print(\"\\n=== Admission Process Complete ===\")\n",
        "    print(\"\\nFinal State (saved to admission_data_v2.json):\")\n",
        "    # print(json.dumps(admission_data, indent=2)) # Optionally print\n",
        "\n",
        "    print(\"\\n--- Final Director's Log ---\")\n",
        "    for entry in admission_data.get(\"director_log\", []): print(f\"- {entry}\")\n",
        "\n",
        "# --- Function to Handle Director Queries ---\n",
        "def handle_director_query(query: str):\n",
        "    print(f\"\\n--- Handling Director Query: '{query}' ---\")\n",
        "    try:\n",
        "        current_data = load_data()\n",
        "        if not isinstance(current_data.get(\"applications\"), list): print(\"Error: Invalid data format in JSON file.\"); return \"Sorry, the admission data seems corrupted.\"\n",
        "        data_summary = json.dumps(current_data, indent=2)\n",
        "    except Exception as e: print(f\"Error loading data for director query: {e}\"); return \"Sorry, I couldn't load the latest admission data.\"\n",
        "    prompt = f\"\"\"\n",
        "You are assisting the University Director...\n",
        "Admission Data:\n",
        "{data_summary}\n",
        "Director's Query: {query}\n",
        "Provide a clear and concise answer...\n",
        "\"\"\"\n",
        "    try:\n",
        "        response = llm_report.invoke([HumanMessage(content=prompt)]); answer = response.content\n",
        "        print(\"\\nDirector's Answer:\"); print(answer); return answer\n",
        "    except Exception as e: print(f\"Error handling director query: {e}\"); return f\"Sorry, I encountered an error: {e}\"\n",
        "\n",
        "# --- Run the entire process ---\n",
        "run_admission_process_with_uploads()\n",
        "\n",
        "# --- Example Director Queries ---\n",
        "# print(\"\\n--- Answering Director Queries ---\")\n",
        "# handle_director_query(\"How many students applied in total?\")\n",
        "# handle_director_query(\"How many students were shortlisted?\")\n",
        "# handle_director_query(\"Give me the names of the shortlisted students.\")\n",
        "# handle_director_query(\"How many loans were approved and what is the remaining budget?\")\n",
        "# handle_director_query(\"Why was Bob rejected?\")\n",
        "# handle_director_query(\"What is the status of Anjali Sharma's application?\")\n",
        "# handle_director_query(\"Which students had their loan rejected due to income?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xs2hGu8QdhU0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
