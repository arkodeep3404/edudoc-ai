{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4796d4b-4b28-43bb-b950-4c44bbff4444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this if already installed in your Jupyter environment\n",
    "!pip install -q langgraph langchain langchain_openai pypdf2 pillow pymupdf faiss-cpu langchain_community reportlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b4d57-1c18-4359-8307-2d92ec2183ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-..................\"  # Replace with your actual OpenAI key\n",
    "SENDER_EMAIL = \"........@........\"\n",
    "SENDER_PASSWORD = \".....................\"\n",
    "\n",
    "import json\n",
    "import re\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Annotated, TypedDict\n",
    "from email.message import EmailMessage\n",
    "import smtplib\n",
    "from pydantic import BaseModel, Field\n",
    "from PIL import Image\n",
    "import base64\n",
    "import fitz\n",
    "import PyPDF2\n",
    "\n",
    "# LangChain / LangGraph\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d146a107-5ddb-4b30-b906-1d73ce8078a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "\n",
    "# === Constants ===\n",
    "DATA_FILE = \"admission_data_v2.json\"\n",
    "BACKUP_FILE = \"admission_data_backup.json\"\n",
    "UPLOAD_DIR = \"uploaded_files\"\n",
    "\n",
    "Path(UPLOAD_DIR).mkdir(exist_ok=True)\n",
    "\n",
    "# === Default Structures ===\n",
    "DEFAULT_DATA_STRUCTURE = {\n",
    "    \"applications\": [],\n",
    "    \"eligibility_criteria\": {\n",
    "        \"min_class10_pcm_perc\": 60,\n",
    "        \"min_class12_pcm_perc\": 60,\n",
    "        \"max_wbjee_rank\": 10000,\n",
    "        \"max_income_for_loan_lpa\": 5.0,\n",
    "        \"required_docs\": [\"Marksheet\", \"Aadhaar\"]\n",
    "    },\n",
    "    \"university_capacity\": 3,\n",
    "    \"loan_budget\": 12000,\n",
    "    \"fee_amount\": 5000,\n",
    "    \"director_log\": [],\n",
    "    \"criteria_file_path\": None\n",
    "}\n",
    "\n",
    "DEFAULT_APPLICATION_STRUCTURE = {\n",
    "    \"app_id\": \"\",\n",
    "    \"applicant_name_marksheet\": None,\n",
    "    \"applicant_email\": None,\n",
    "    \"marks\": {\"class10_pcm_perc\": None, \"class12_pcm_perc\": None},\n",
    "    \"wbjee_rank\": None,\n",
    "    \"aadhaar_name\": None,\n",
    "    \"aadhaar_number\": None,\n",
    "    \"marksheet_pdf_path\": None,\n",
    "    \"aadhaar_pdf_path\": None,\n",
    "    \"family_income_lpa\": None,\n",
    "    \"loan_requested\": False,\n",
    "    \"extraction_status\": \"Pending\",\n",
    "    \"validation_status\": \"Pending\",\n",
    "    \"validation_reason\": None,\n",
    "    \"shortlist_status\": \"Pending\",\n",
    "    \"communication_status\": \"Not Sent\",\n",
    "    \"loan_status\": \"Not Applicable\",\n",
    "    \"loan_rejection_reason\": None,\n",
    "    \"fee_slip_status\": \"Not Sent\"\n",
    "}\n",
    "\n",
    "# === Load Function with Auto Recovery ===\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Loads admission data from the JSON file.\n",
    "    If the file doesn't exist or is corrupted, it creates and returns the default structure.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(DATA_FILE):\n",
    "        print(f\"üìÅ '{DATA_FILE}' not found. Creating new data file.\")\n",
    "        with open(DATA_FILE, 'w') as f:\n",
    "            json.dump(DEFAULT_DATA_STRUCTURE, f, indent=4)\n",
    "        return DEFAULT_DATA_STRUCTURE\n",
    "\n",
    "    try:\n",
    "        with open(DATA_FILE, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Safety check for keys\n",
    "        if \"applications\" not in data:\n",
    "            data[\"applications\"] = []\n",
    "        if \"eligibility_criteria\" not in data:\n",
    "            data[\"eligibility_criteria\"] = DEFAULT_DATA_STRUCTURE[\"eligibility_criteria\"]\n",
    "\n",
    "        return data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error reading '{DATA_FILE}': {e}. Creating fresh file.\")\n",
    "        with open(DATA_FILE, 'w') as f:\n",
    "            json.dump(DEFAULT_DATA_STRUCTURE, f, indent=4)\n",
    "        return DEFAULT_DATA_STRUCTURE\n",
    "\n",
    "# === Save Function with Auto Backup ===\n",
    "def save_data(data):\n",
    "    \"\"\"\n",
    "    Saves admission data to the JSON file.\n",
    "    Also keeps a backup copy in case something breaks.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Save primary file\n",
    "        with open(DATA_FILE, 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "        print(\"üíæ Data saved successfully.\")\n",
    "\n",
    "        # Save backup\n",
    "        with open(BACKUP_FILE, 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "        print(\"üõ°Ô∏è Backup created.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to save data to '{DATA_FILE}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5739e323-b4b8-4376-912f-ad6e5c7eb0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_application_graph(student_data: dict):\n",
    "    \"\"\"\n",
    "    Trigger LangGraph processing for a single student application.\n",
    "    Used directly by the Streamlit chatbot after collecting user data.\n",
    "    \"\"\"\n",
    "    print(f\"üì• Saving application for {student_data.get('name')} | ID: {student_data['app_id']}\")\n",
    "    admission_data = load_data()\n",
    "\n",
    "    new_app = DEFAULT_APPLICATION_STRUCTURE.copy()\n",
    "    new_app[\"app_id\"] = student_data[\"app_id\"]\n",
    "    new_app[\"marksheet_pdf_path\"] = student_data.get(\"marksheet_pdf_path\")\n",
    "    new_app[\"aadhaar_pdf_path\"] = student_data.get(\"aadhaar_pdf_path\")\n",
    "    new_app[\"loan_requested\"] = student_data.get(\"loan_requested\", False)\n",
    "    new_app[\"family_income_lpa\"] = student_data.get(\"family_income_lpa\", None)\n",
    "\n",
    "    admission_data[\"applications\"].append(new_app)\n",
    "    app_index = len(admission_data[\"applications\"]) - 1\n",
    "\n",
    "    state = {\n",
    "        \"admission_data\": admission_data,\n",
    "        \"current_app_index\": app_index,\n",
    "        \"current_run_log\": [],\n",
    "        \"extracted_marksheet_data\": None,\n",
    "        \"extracted_aadhaar_data\": None\n",
    "    }\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": f\"app_process_{student_data['app_id']}\"}}\n",
    "\n",
    "    try:\n",
    "        final_state = compiled_process_app_graph.invoke(state, config=config)\n",
    "        save_data(final_state[\"admission_data\"])\n",
    "        print(\"‚úÖ Application processed and saved successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error while running LangGraph: {e}\")\n",
    "        admission_data[\"director_log\"].append(f\"ERROR processing application ID: {student_data['app_id']}: {e}\")\n",
    "        save_data(admission_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "790a1c88-969a-4cee-b919-fa3236bc4c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_director_query(query: str):\n",
    "    \"\"\"\n",
    "    Allows an admin to ask questions about the current admission state.\n",
    "    Powered by GPT to summarize or answer custom queries.\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîç Handling Director Query: '{query}'\")\n",
    "\n",
    "    try:\n",
    "        current_data = load_data()\n",
    "        data_summary = json.dumps(current_data, indent=2)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading data for query: {e}\")\n",
    "        return \"‚ö†Ô∏è Unable to load current admission data.\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an intelligent assistant helping a university admission director.\n",
    "    The following is the current admission data:\n",
    "    {data_summary}\n",
    "\n",
    "    Now answer this query clearly and concisely:\n",
    "    {query}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        print(\"‚úÖ Query answered successfully.\")\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating response: {e}\")\n",
    "        return f\"‚ö†Ô∏è An error occurred while answering the query: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7017d51d-f764-440d-a800-73858ef38ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from reportlab.pdfgen import canvas\n",
    "\n",
    "# === Utility: Extract Text from PDF ===\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            text = \" \".join([page.extract_text() or \"\" for page in reader.pages])\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to extract text from {pdf_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# === Node: Extract Data ===\n",
    "def data_extraction_node(state: ProcessAppState) -> ProcessAppState:\n",
    "    index = state.current_app_index\n",
    "    app = state.admission_data[\"applications\"][index]\n",
    "\n",
    "    marksheet_text = extract_text_from_pdf(app[\"marksheet_pdf_path\"])\n",
    "    aadhaar_text = extract_text_from_pdf(app[\"aadhaar_pdf_path\"])\n",
    "\n",
    "    # Naive mock parsing (replace with regex/NER)\n",
    "    app[\"applicant_name_marksheet\"] = \"Student Name\" if \"Student\" in marksheet_text else \"Unknown\"\n",
    "    app[\"aadhaar_name\"] = \"Student Name\" if \"Student\" in aadhaar_text else \"Unknown\"\n",
    "    app[\"aadhaar_number\"] = \"XXXX-XXXX-XXXX\"\n",
    "\n",
    "    state.extracted_marksheet_data = {\"text\": marksheet_text}\n",
    "    state.extracted_aadhaar_data = {\"text\": aadhaar_text}\n",
    "    state.admission_data[\"applications\"][index] = app\n",
    "    state.current_run_log.append(\"üßæ PDF data extracted.\")\n",
    "    return state\n",
    "\n",
    "# === Node: Validate Application ===\n",
    "def validation_node(state: ProcessAppState) -> ProcessAppState:\n",
    "    index = state.current_app_index\n",
    "    app = state.admission_data[\"applications\"][index]\n",
    "\n",
    "    valid = (\n",
    "        app[\"marksheet_pdf_path\"] and app[\"aadhaar_pdf_path\"] and\n",
    "        app[\"applicant_name_marksheet\"] != \"Unknown\" and\n",
    "        app[\"aadhaar_name\"] != \"Unknown\"\n",
    "    )\n",
    "\n",
    "    if valid:\n",
    "        app[\"validation_status\"] = \"Valid\"\n",
    "        state.current_run_log.append(\"‚úÖ Application validated.\")\n",
    "    else:\n",
    "        app[\"validation_status\"] = \"Invalid\"\n",
    "        app[\"validation_reason\"] = \"Name mismatch or missing document\"\n",
    "        state.current_run_log.append(\"‚ùå Validation failed.\")\n",
    "\n",
    "    state.admission_data[\"applications\"][index] = app\n",
    "    return state\n",
    "\n",
    "# === Node: Communicate Application Status ===\n",
    "def communication_node(state: ProcessAppState) -> ProcessAppState:\n",
    "    index = state.current_app_index\n",
    "    app = state.admission_data[\"applications\"][index]\n",
    "\n",
    "    msg = EmailMessage()\n",
    "    msg[\"Subject\"] = f\"Application Status - ID {app['app_id']}\"\n",
    "    msg[\"From\"] = SENDER_EMAIL\n",
    "    msg[\"To\"] = app[\"applicant_email\"]\n",
    "    content = f\"\"\"\n",
    "    Hello {app['applicant_name_marksheet']},\n",
    "\n",
    "    Your application (ID: {app['app_id']}) has been {app['validation_status']}.\n",
    "\n",
    "    Loan status: {app['loan_status']}\n",
    "\n",
    "    Thank you,\n",
    "    Admissions Team\n",
    "    \"\"\"\n",
    "    msg.set_content(content)\n",
    "\n",
    "    try:\n",
    "        server = smtplib.SMTP_SSL('smtp.gmail.com', 465)\n",
    "        server.login(SENDER_EMAIL, SENDER_PASSWORD)\n",
    "        server.send_message(msg)\n",
    "        server.quit()\n",
    "        app[\"communication_status\"] = \"Email Sent\"\n",
    "        state.current_run_log.append(\"üìß Email sent successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Email failed: {e}\")\n",
    "        app[\"communication_status\"] = \"Failed to send\"\n",
    "        state.current_run_log.append(f\"‚ùå Email error: {e}\")\n",
    "\n",
    "    state.admission_data[\"applications\"][index] = app\n",
    "    return state\n",
    "\n",
    "# === Node: Loan and Fee Slip Handling ===\n",
    "def loan_processing_node(state: ProcessAppState) -> ProcessAppState:\n",
    "    index = state.current_app_index\n",
    "    app = state.admission_data[\"applications\"][index]\n",
    "    budget = state.admission_data.get(\"loan_budget\", 0)\n",
    "\n",
    "    if app.get(\"loan_requested\"):\n",
    "        income = app.get(\"family_income_lpa\", 10)\n",
    "        if income <= 5.0 and budget >= 5000:\n",
    "            app[\"loan_status\"] = \"Approved\"\n",
    "            state.admission_data[\"loan_budget\"] -= 5000\n",
    "            state.current_run_log.append(\"üè¶ Loan approved.\")\n",
    "        else:\n",
    "            app[\"loan_status\"] = \"Rejected\"\n",
    "            app[\"loan_rejection_reason\"] = \"Income too high or insufficient budget\"\n",
    "            state.current_run_log.append(\"‚ùå Loan rejected.\")\n",
    "    else:\n",
    "        app[\"loan_status\"] = \"Not Requested\"\n",
    "        state.current_run_log.append(\"üíº Loan not requested.\")\n",
    "\n",
    "    # Generate and save fee slip\n",
    "    slip_path = Path(UPLOAD_DIR) / f\"{app['app_id']}_fee_slip.pdf\"\n",
    "    try:\n",
    "        c = canvas.Canvas(str(slip_path))\n",
    "        c.drawString(100, 750, f\"Fee Slip for {app['applicant_name_marksheet']}\")\n",
    "        c.drawString(100, 730, f\"App ID: {app['app_id']}\")\n",
    "        c.drawString(100, 710, f\"Loan Status: {app['loan_status']}\")\n",
    "        c.drawString(100, 690, f\"Date: {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "        c.save()\n",
    "        app[\"fee_slip_status\"] = \"Generated\"\n",
    "        state.current_run_log.append(\"üßæ Fee slip generated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fee slip error: {e}\")\n",
    "        app[\"fee_slip_status\"] = \"Failed\"\n",
    "\n",
    "    state.admission_data[\"applications\"][index] = app\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dae9b01-7922-4da5-beec-3547b7bdda26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from email.message import EmailMessage\n",
    "from reportlab.pdfgen import canvas\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f87b433-92af-40d0-807a-1c9f918d0c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangGraph for single application compiled successfully.\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "\n",
    "# ‚úÖ Updated schema for LangGraph\n",
    "class ProcessAppState(BaseModel):\n",
    "    admission_data: dict\n",
    "    current_app_index: int\n",
    "    current_run_log: List[str] = Field(default_factory=list)\n",
    "    extracted_marksheet_data: Optional[dict] = None\n",
    "    extracted_aadhaar_data: Optional[dict] = None\n",
    "\n",
    "# ‚úÖ Define and compile the LangGraph\n",
    "process_app_workflow = StateGraph(ProcessAppState)\n",
    "\n",
    "# Add your node functions here:\n",
    "# These functions must be defined elsewhere in your notebook or module\n",
    "# For example:\n",
    "# def data_extraction_node(state: ProcessAppState): ...\n",
    "# def validation_node(state: ProcessAppState): ...\n",
    "# def communication_node(state: ProcessAppState): ...\n",
    "# def loan_processing_node(state: ProcessAppState): ...\n",
    "\n",
    "process_app_workflow.add_node(\"extract_data\", data_extraction_node)\n",
    "process_app_workflow.add_node(\"validate_application\", validation_node)\n",
    "process_app_workflow.add_node(\"communicate_status\", communication_node)\n",
    "process_app_workflow.add_node(\"check_loan_request\", loan_processing_node)\n",
    "\n",
    "# Define flow structure\n",
    "process_app_workflow.set_entry_point(\"extract_data\")\n",
    "process_app_workflow.add_edge(\"extract_data\", \"validate_application\")\n",
    "process_app_workflow.add_edge(\"validate_application\", \"communicate_status\")\n",
    "process_app_workflow.add_edge(\"communicate_status\", \"check_loan_request\")\n",
    "process_app_workflow.set_finish_point(\"check_loan_request\")\n",
    "\n",
    "# Compile it\n",
    "compiled_process_app_graph = process_app_workflow.compile()\n",
    "print(\"‚úÖ LangGraph for single application compiled successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8752012-8b76-40a2-a15e-d107859e9308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "def run_admission_process_with_uploads():\n",
    "    \"\"\"\n",
    "    Jupyter-based flow for uploading and processing multiple student applications manually.\n",
    "    \"\"\"\n",
    "    print(\"üìã Starting batch admission process via notebook...\")\n",
    "    admission_data = load_data()\n",
    "    admission_data[\"applications\"] = []\n",
    "\n",
    "    while True:\n",
    "        cont = input(\"üì§ Upload a new application? (yes/no): \").strip().lower()\n",
    "        if cont != \"yes\":\n",
    "            break\n",
    "\n",
    "        app_id = str(uuid.uuid4())\n",
    "        print(f\"\\nüìé Application ID: {app_id}\")\n",
    "\n",
    "        marksheet_path = input(\"Path to Marksheet PDF: \").strip()\n",
    "        aadhaar_path = input(\"Path to Aadhaar PDF: \").strip()\n",
    "        income_str = input(\"Family income in LPA (e.g., 4.5): \").strip()\n",
    "        loan_req = input(\"Apply for loan? (yes/no): \").strip().lower()\n",
    "\n",
    "        try:\n",
    "            income = float(income_str)\n",
    "        except ValueError:\n",
    "            income = None\n",
    "\n",
    "        loan_requested = loan_req == \"yes\"\n",
    "\n",
    "        new_app = DEFAULT_APPLICATION_STRUCTURE.copy()\n",
    "        new_app[\"app_id\"] = app_id\n",
    "        new_app[\"marksheet_pdf_path\"] = marksheet_path\n",
    "        new_app[\"aadhaar_pdf_path\"] = aadhaar_path\n",
    "        new_app[\"family_income_lpa\"] = income\n",
    "        new_app[\"loan_requested\"] = loan_requested\n",
    "\n",
    "        admission_data[\"applications\"].append(new_app)\n",
    "\n",
    "    if not admission_data[\"applications\"]:\n",
    "        print(\"üö´ No applications to process.\")\n",
    "        return\n",
    "\n",
    "    # Run processing graph for each application\n",
    "    for i, app in enumerate(admission_data[\"applications\"]):\n",
    "        state = {\n",
    "            \"admission_data\": admission_data,\n",
    "            \"current_app_index\": i,\n",
    "            \"current_run_log\": [],\n",
    "            \"extracted_marksheet_data\": None,\n",
    "            \"extracted_aadhaar_data\": None\n",
    "        }\n",
    "        config = {\"configurable\": {\"thread_id\": f\"app_process_{app['app_id']}\"}}\n",
    "        try:\n",
    "            final_state = compiled_process_app_graph.invoke(state, config=config)\n",
    "            admission_data = final_state[\"admission_data\"]\n",
    "            print(f\"‚úÖ Processed application {i+1}/{len(admission_data['applications'])}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing application {i+1}: {e}\")\n",
    "            continue\n",
    "\n",
    "    save_data(admission_data)\n",
    "    print(\"üìÅ All applications processed and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e24be-2ba9-4ce4-a113-68e66ad3c4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
